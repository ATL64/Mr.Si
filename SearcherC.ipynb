{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796dddba-0da6-4285-9bf1-6468bbdc62b9",
   "metadata": {},
   "source": [
    "# Google Searcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a945c0e-fceb-4097-bc58-8a7705ef878d",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create an automated google searcher leveraging the semantic capabilities of GPT-3.\n",
    "The use case is for a user who has an arbitrary question they want answered (one would ordinarily google specific keywords for this and go find the answer in some website found in the google results).\n",
    "This is the following cognitive process we want to replicate:\n",
    "1. The input string is the question the user wants answered.  We want to extract multiple strings from it via GPT-3, each of them containing a proposal for a google search.  Ask GPT-3 to output as python list.\n",
    "2. Execute each google search\n",
    "    \n",
    "    2.a. retrieve the top n urls\n",
    "    \n",
    "    2.b. fetch the website's text and do embeddings for semantic search\n",
    "    \n",
    "3. Store page urls of the google search in a table\n",
    "4. Use GPT-3 to evaluate the credibility score of each website\n",
    "5. Execute a semantic search for the input question against the text corpus (which should be labeled with the urls as metadata or something) to get top m candidates.\n",
    "6. Shoot the question against each of the candidates using GPT-3\n",
    "7. Display answers and url, ordered by credibility score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42275eaf-57c2-4344-8acf-1f7fd85d5b81",
   "metadata": {},
   "source": [
    "### Index:\n",
    "\n",
    "0. Imports & functions\n",
    "\n",
    "1. Create Google Searches\n",
    "\n",
    "2. a. Top n URLS\n",
    "\n",
    "2. b. Embeddings\n",
    "\n",
    "3. URL Table\n",
    "\n",
    "4. Credibility Score\n",
    "\n",
    "5. Semantic Search with credibility\n",
    "\n",
    "6. GPT-3 Answers\n",
    "\n",
    "7. Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53477f8c-430f-4d62-99d1-7ed1ab727e36",
   "metadata": {},
   "source": [
    "You can skip all the steps and go down to the bottom to see a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91084686-935f-4654-bb21-0fa2bc6339b3",
   "metadata": {},
   "source": [
    "## 0. Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf6705-c20c-48d4-9183-0d0763c78eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import openai\n",
    "from time import time, sleep\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import ast\n",
    "import requests\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import tiktoken\n",
    "import json\n",
    "import bs4 as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ae51884-8b14-487a-94a1-502828a9d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath):\n",
    "    # This function opens a file located at the specified filepath and returns a string containing the file's content.\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    # This function saves the content in a file located at the specified filepath.\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "# change path to where you store your credentials\n",
    "openai.api_key = open_file('creds/creds.txt')\n",
    "\n",
    "rapid_api_key = open_file('creds/rapid_api_key.txt')\n",
    "rapid_api_host = open_file('creds/rapid_api_host.txt')\n",
    "\n",
    "def gpt3_completion(prompt, label='gpt3', engine='text-davinci-003', temp=0, top_p=1.0, tokens=400, freq_pen=2.0, pres_pen=2.0, stop=['asdfasdf', 'asdasdf']):\n",
    "    # This function uses OpenAI's GPT-3 Engine to generate completions for the given prompt.\n",
    "    max_retry = 5\n",
    "    retry = 0\n",
    "    prompt = prompt.encode(encoding='ASCII', errors='ignore').decode()  # force it to fix any unicode errors\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=engine,\n",
    "                prompt=prompt,\n",
    "                temperature=temp,\n",
    "                max_tokens=tokens,\n",
    "                top_p=top_p,\n",
    "                frequency_penalty=freq_pen,\n",
    "                presence_penalty=pres_pen,\n",
    "                stop=stop)\n",
    "            text = response['choices'][0]['text'].strip()\n",
    "            text = re.sub('\\s+', ' ', text)\n",
    "            return text\n",
    "        except Exception as oops:\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                return \"GPT3 error: %s\" % oops\n",
    "            print('Error communicating with OpenAI:', oops)\n",
    "            sleep(1)\n",
    "            \n",
    "def deduplicate_list(x):\n",
    "    # This function removes duplicate elements from a list and returns the deduplicated list.\n",
    "    return list(dict.fromkeys(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23442dab-a02b-4e0c-b552-d74075e79d74",
   "metadata": {},
   "source": [
    "## 1. Search strings\n",
    "Here we obtain search strings from a question I want to answer.  Our initial question for the testing of the functions below will be \"How long until we cure cancer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f123f6-cc43-475a-aa1f-64f26ee1218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question\n",
    "my_question = \"How long until we cure cancer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6b751b7-c59e-4a42-ae88-60fb8b713f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_strings(input):\n",
    "    ### input is a string, containing the initial question of the user\n",
    "    ### Returns string containing a JSON formatted response\n",
    "    question = input\n",
    "    prompt = \"\"\"The following is a question a user has.  Please propose a list of between 5 and 10 potentially useful Google Searches the user can execute to retrieve useful information to answer the question.  The list should be output as a python list, using double quotes for strings.\n",
    "    QUESTION:\n",
    "    {0}\n",
    "\n",
    "    LIST RESPONSE: \"\"\".format(question)\n",
    "    gpt_response = gpt3_completion(prompt)\n",
    "    try:\n",
    "        search_list = ast.literal_eval(gpt_response)\n",
    "    except:\n",
    "        gpt_response = gpt3_completion(prompt, temp=0.6)\n",
    "        search_list = ast.literal_eval(gpt_response)\n",
    "    return search_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10448b2f-9cfd-4547-bd3c-9dbf4e72b985",
   "metadata": {},
   "source": [
    "Here are some examples of proposed searches by GPT-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51c918c1-a3ca-48b8-b050-3c5240fe6d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timeline for curing cancer',\n",
       " 'when will we cure cancer?',\n",
       " 'progress in curing cancer research',\n",
       " 'how close are scientists to a cure for cancer?',\n",
       " 'what is the prognosis of finding a cure for all cancers?',\n",
       " 'cancer breakthroughs timeline',\n",
       " 'current progress towards a universal treatment or prevention of any type of malignant tumor ',\n",
       " 'scientific advances that could lead to cures and treatments against different types of tumors ',\n",
       " 'research on new methods to treat various forms of neoplasms']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search_strings(my_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4f31b-9867-4d9e-9df4-d38d6519364b",
   "metadata": {},
   "source": [
    "## 2. a. Top n URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c0ae0-1ae5-4d5b-b499-05c0d364d011",
   "metadata": {},
   "source": [
    "We will want do a google search with each of the queries in the list above and fetch a fixed number of urls from each of the search results (we will deduplicate and use them later on).  For that we will need the following function which executes a google search and returns the top N links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a79e402a-62ef-487b-b813-682fd2155b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When will we cure cancer?\"\n",
    "n = 10\n",
    "\n",
    "def get_top_urls(query, n, pprint = True):\n",
    "    # input is a google search (a string) and an integer n\n",
    "    # output top n urls\n",
    "    url = \"https://google-search72.p.rapidapi.com/search\"\n",
    "    #num is number n of top results\n",
    "    querystring = {\"query\":query,\"gl\":\"us\",\"lr\":\"en\",\"num\":str(n),\"start\":\"0\",\"sort\":\"relevance\"}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": rapid_api_key,\n",
    "        \"X-RapidAPI-Host\": rapid_api_host\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    if pprint:\n",
    "        global resp_debug \n",
    "        resp_debug = response.text\n",
    "    data = json.loads(response.text)\n",
    "    # Get list of top urls\n",
    "    top_urls = []\n",
    "    for item in data['items']:\n",
    "        if not item['link'].endswith(\".pdf\"):\n",
    "            top_urls.append(item['link'])\n",
    "        \n",
    "    return top_urls\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fe7538e-dd4d-4ab8-83ab-7c5ec56dfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_urls = get_top_urls(query,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ef37f-6c7c-47bc-94ee-8e76d539e090",
   "metadata": {},
   "source": [
    "Here are the top 3 urls from the google search (in order returned by google search results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f823b2d5-d237-4c5e-85c2-f9f06b2d11b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer',\n",
       " 'https://www.foxchase.org/blog/are-we-any-closer-curing-cancer',\n",
       " 'https://www.hsph.harvard.edu/magazine/magazine_article/the-cancer-miracle-isnt-a-cure-its-prevention/']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a76012-8c09-4008-8d72-bb7c0c34c1d3",
   "metadata": {},
   "source": [
    "## 2. b. Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86833349-07ab-42e8-879a-b25cdd6705b2",
   "metadata": {},
   "source": [
    "Now we want to store the text from the websites in encoded format to do the semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "53378185-cdd8-4b15-a6f9-ea3faff23d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to fetch the text\n",
    "def get_website(url):\n",
    "    # The input is a string containing the desired url\n",
    "    # The output is a string containing the text from the website at the url\n",
    "    # The function uses the requests library to get the text from the website\n",
    "    # at the url and returns the text\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.text\n",
    "    except:\n",
    "        return 'Error'\n",
    "\n",
    "def extract_clean_text(site):\n",
    "    # The input is a string containing all the text from a website, including the HTML\n",
    "    # The output is a string containing only the human readable text i.e. without all the HTML tags\n",
    "    # The function uses the BeautifulSoup library to parse the HTML and return only the human readable text\n",
    "    # Parse the HTML as a string\n",
    "    soup = bs.BeautifulSoup(site,'html.parser')\n",
    "    # Get the text out of the soup and return it\n",
    "    text = ''.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    return text\n",
    "\n",
    "def split_string(string, x = 2500): \n",
    "    # Split the string into n-sized chunks. Last chunk might be smol.\n",
    "    res=[string[y-x:y] for y in range(x, len(string)+x,x)]\n",
    "    #split_strings.append(res) \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8de83cbb-638a-4cb5-bb2e-487632c2f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5ea7ce7-b102-4003-b009-f1ecbd836fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty DataFrame with specific column names & types\n",
    "df = pd.DataFrame({'url': pd.Series(dtype='str'),\n",
    "                   'snippet_id': pd.Series(dtype='str'),\n",
    "                   'text': pd.Series(dtype='str'),\n",
    "                  'embedding': pd.Series(dtype='str')})\n",
    "# Using NumPy\n",
    "dtypes = np.dtype(\n",
    "    [\n",
    "        (\"url\", str),\n",
    "        (\"snippet_id\", str),\n",
    "        (\"text\", str),\n",
    "        (\"embedding\",str)\n",
    "    ]\n",
    ")\n",
    "df = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "\n",
    "for url in top_urls:\n",
    "    text = get_website(url)\n",
    "    clean = extract_clean_text(text)\n",
    "    snippet_list = split_string(clean, 2500)\n",
    "    #url_list = [url] * len(snippet_list)     \n",
    "    encoding_list = [get_embedding(snippet, engine=embedding_model) for snippet in snippet_list]\n",
    "    for i in range(len(snippet_list)):\n",
    "        df = pd.concat([df,pd.DataFrame({'url': [url], 'snippet_id': [i], 'text':[snippet_list[i]], 'embedding': [encoding_list[i]]})], ignore_index=True) \n",
    "\n",
    "   \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6f72ebf-58bc-4017-a2f9-1015e9d58d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(top_urls, pprint = True):\n",
    "    # Input is a deduplicated list of urls\n",
    "    # Output is a dataframe containing url, snippet_id, text, embedding obtained by fetching the website and calling openai\n",
    "    df = pd.DataFrame({'url': pd.Series(dtype='str'),\n",
    "                   'snippet_id': pd.Series(dtype='str'),\n",
    "                   'text': pd.Series(dtype='str'),\n",
    "                  'embedding': pd.Series(dtype='str')})\n",
    "    # Using NumPy\n",
    "    dtypes = np.dtype(\n",
    "        [\n",
    "            (\"url\", str),\n",
    "            (\"snippet_id\", str),\n",
    "            (\"text\", str),\n",
    "            (\"embedding\",str)\n",
    "        ]\n",
    "    )\n",
    "    df = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "    all_df_list = []\n",
    "    for url in top_urls:\n",
    "        text = get_website(url)\n",
    "        if pprint:\n",
    "            print(url)\n",
    "        if text =='Error':\n",
    "            continue\n",
    "        try:\n",
    "            clean = extract_clean_text(text)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        snippet_list = split_string(clean, 2500)\n",
    "        #url_list = [url] * len(snippet_list)   \n",
    "        if pprint:\n",
    "            print('running encoder')\n",
    "        encoding_list = [get_embedding(snippet, engine=embedding_model) for snippet in snippet_list]\n",
    "        if pprint:\n",
    "            print('finished encoder')\n",
    "            print('adppending to dataframe')\n",
    "        for i in range(len(snippet_list)):\n",
    "            all_df_list.append([url, i, snippet_list[i], encoding_list[i]])\n",
    "            #print(all_df_list[i][0])\n",
    "            #print(all_df_list[i][1])\n",
    "            #df = pd.concat([df,pd.DataFrame({'url': [url], 'snippet_id': [i], 'text':[snippet_list[i]], 'embedding': [encoding_list[i]]})], ignore_index=True) \n",
    "        all_df = pd.concat([df,pd.DataFrame(all_df_list, columns=df.columns)], ignore_index=True)       \n",
    "    return all_df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c13ab-80c0-4c4e-afa7-d9e25ac525fc",
   "metadata": {},
   "source": [
    "In the table below, you can now see we have url, text snippet, and embedding of the text snippet into a vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "631769c4-2cd3-4e48-aee8-5654bdaeff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "running encoder\n",
      "finished encoder\n",
      "adppending to dataframe\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "0\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "1\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "2\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "3\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "4\n",
      "https://www.foxchase.org/blog/are-we-any-closer-curing-cancer\n",
      "running encoder\n",
      "finished encoder\n",
      "adppending to dataframe\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "0\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "1\n",
      "https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>0</td>\n",
       "      <td>We asked three cancer experts - Nobel laureate...</td>\n",
       "      <td>[0.012906081974506378, -0.005089065060019493, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>1</td>\n",
       "      <td>ces. They are slightly modified bacterial plas...</td>\n",
       "      <td>[-0.013120053336024284, 0.00935688428580761, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>2</td>\n",
       "      <td>em is stimulated to attack the cancer) has als...</td>\n",
       "      <td>[-0.007977260276675224, -0.0039186542853713036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>3</td>\n",
       "      <td>sk and to help detect certain cancers early.Fo...</td>\n",
       "      <td>[0.027712570503354073, -0.0203661248087883, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>4</td>\n",
       "      <td>shape the Horizon Europe work programme, an i...</td>\n",
       "      <td>[-0.001030220533721149, 0.00011779329361161217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url snippet_id  \\\n",
       "0  https://ec.europa.eu/research-and-innovation/e...          0   \n",
       "1  https://ec.europa.eu/research-and-innovation/e...          1   \n",
       "2  https://ec.europa.eu/research-and-innovation/e...          2   \n",
       "3  https://ec.europa.eu/research-and-innovation/e...          3   \n",
       "4  https://ec.europa.eu/research-and-innovation/e...          4   \n",
       "\n",
       "                                                text  \\\n",
       "0  We asked three cancer experts - Nobel laureate...   \n",
       "1  ces. They are slightly modified bacterial plas...   \n",
       "2  em is stimulated to attack the cancer) has als...   \n",
       "3  sk and to help detect certain cancers early.Fo...   \n",
       "4   shape the Horizon Europe work programme, an i...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.012906081974506378, -0.005089065060019493, ...  \n",
       "1  [-0.013120053336024284, 0.00935688428580761, -...  \n",
       "2  [-0.007977260276675224, -0.0039186542853713036...  \n",
       "3  [0.027712570503354073, -0.0203661248087883, 0....  \n",
       "4  [-0.001030220533721149, 0.00011779329361161217...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df(top_urls[0:2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "195ded43-10fc-4eb2-bc02-a4b6d397238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through the reviews for a specific product\n",
    "def search_snippets(df, question, n=3, pprint=False):\n",
    "    # input is a df with embeddings of the texts (it contains url, snippet_id, snippet text as well)\n",
    "    # output is the top n results, in the same format as df\n",
    "    question_embedding = get_embedding(\n",
    "        question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, question_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)\n",
    "    )\n",
    "    if pprint:\n",
    "        for r in results:\n",
    "            print(r[:200])\n",
    "            print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26de9bb-3fa2-46e5-826f-71c09172720d",
   "metadata": {},
   "source": [
    "Below you can see the similarity column.  First we embedded the initial question as well, then found nearby vectors i.e. computed the similarity of that particular snippet with respect to our initial query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5637444f-a558-41f7-8fab-f79c53c76419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\n",
      "\n",
      "snippet_id\n",
      "\n",
      "text\n",
      "\n",
      "encoding\n",
      "\n",
      "embedding\n",
      "\n",
      "similarity\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>encoding</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://www.icr.ac.uk/blogs/science-talk/page-...</td>\n",
       "      <td>0</td>\n",
       "      <td>We’ve learned a lot about cancer in the last d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.013241356238722801, -0.00850482378154993, 0...</td>\n",
       "      <td>0.871770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://www.icr.ac.uk/blogs/science-talk/page-...</td>\n",
       "      <td>1</td>\n",
       "      <td>of patients and the public in wanting cancer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.01164434663951397, 0.004861883819103241, 0...</td>\n",
       "      <td>0.852989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.foxchase.org/blog/are-we-any-close...</td>\n",
       "      <td>0</td>\n",
       "      <td>Due to a system-wide technology update, we are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.0031348944175988436, 0.004773442167788744,...</td>\n",
       "      <td>0.852107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url snippet_id  \\\n",
       "29  https://www.icr.ac.uk/blogs/science-talk/page-...          0   \n",
       "30  https://www.icr.ac.uk/blogs/science-talk/page-...          1   \n",
       "5   https://www.foxchase.org/blog/are-we-any-close...          0   \n",
       "\n",
       "                                                 text encoding  \\\n",
       "29  We’ve learned a lot about cancer in the last d...      NaN   \n",
       "30   of patients and the public in wanting cancer ...      NaN   \n",
       "5   Due to a system-wide technology update, we are...      NaN   \n",
       "\n",
       "                                            embedding  similarity  \n",
       "29  [0.013241356238722801, -0.00850482378154993, 0...    0.871770  \n",
       "30  [-0.01164434663951397, 0.004861883819103241, 0...    0.852989  \n",
       "5   [-0.0031348944175988436, 0.004773442167788744,...    0.852107  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_snippets(df, my_question, n=3, pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f799e20a-cf4c-4a75-be2a-585354fd126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We asked three cancer experts - Nobel laureate Professor Harald zur Hausen, Professor Walter Ricciardi and Dr Elisabete Weiderpass – for their thoughts on curing cancer. They all sit on the EU’s Horizon Europe mission board for cancer and will help to define a concrete target for Europe in this area over the next decade.Prof. Harald zur Hausen, German Cancer Research Center, Heidelberg‘Evidence of infections linked to cancer provide hope of preventing up to half of all cancers’If we can ever cure cancer completely – that is an open question which I cannot answer. We have a good chance of drastically reducing the incidence of cancers, but what we see at present is that the incidence, or occurrence, of cancer is increasing globally.The mortality of cancer patients is slightly decreasing, but the increase in incidence is not compensated by the decrease in mortality. There are still a large number of cases coming up every year, and if we really want to do something against cancer in the future, we need to stop the increase.We know there are a number of cancer risk factors that can be avoided. At this moment, we also know of about 20% of cancers where infections are involved. We can not only effectively immunise patients against these types of cancer, but virtually eradicate it, in particular Hepatitis B (a cause of liver cancer) and Human Papillomavirus (which Prof. zur Hausen discovered is linked to cervical cancer) where we have vaccines that are presently available.We believe we have evidence that at least 30% more human cancers are also linked to infectious events. This provides at least the hope that in the near future other methods can be developed that will also lead to long-term protection from those diseases – specifically colon cancer, breast cancer, and prostate cancer, where evidence is mounting that specific infectious events play a role.Recently, we discovered a completely new class of infectious agents which are derived originally from plasmids. Plasmids are a kind of mini-chromosome of bacteria, which we find in a very large number of colon cancer patients. These are infections which persist for decades, causing chronic inflammations, and these inflammations are really the cause of oxygen radicals and mutation events in cells that are susceptible to cancer development.We have all the (plasmid) genomes sequenced that we have identified so far, and what came up was really a surprise for us, because they do not represent viral nor bacterial sequen'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6591a54-d215-4fdd-8f88-68dd3e9944b0",
   "metadata": {},
   "source": [
    "## 3.URL Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2535d42-b08d-453a-a23d-ae5bd3282131",
   "metadata": {},
   "source": [
    "Make URL table so we can add a column with the credibility score of that website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af8de8e9-9f5b-4ab6-8e19-3e357b83ac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ec.europa.eu/research-and-innovation/en/horizon-magazine/will-we-ever-cure-cancer',\n",
       " 'https://www.foxchase.org/blog/are-we-any-closer-curing-cancer',\n",
       " 'https://www.hsph.harvard.edu/magazine/magazine_article/the-cancer-miracle-isnt-a-cure-its-prevention/',\n",
       " 'https://futurism.com/neoscope/vaccine-predict-cancer-vaccine-2030',\n",
       " 'https://www.worldwidecancerresearch.org/news-opinion/2021/march/why-havent-we-cured-cancer-yet/',\n",
       " 'https://www.icr.ac.uk/blogs/science-talk/page-details/what-s-coming-for-cancer-in-the-2020s',\n",
       " 'https://www.roswellpark.org/cancertalk/201909/cure-cancer-whats-taking-so-long',\n",
       " 'https://www.verywellhealth.com/will-cancer-ever-be-cured-4686392',\n",
       " 'https://www.theatlantic.com/magazine/archive/2014/01/when-will-genomics-cure-cancer/355739/',\n",
       " 'https://www.cancer.gov/news-events/cancer-currents-blog/2022/mrna-vaccines-to-treat-cancer']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98b1aff1-b978-4469-8eff-3e3e99469c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be populated below\n",
    "df_urls = pd.DataFrame({'url': pd.Series(dtype='str'),\n",
    "                       'score': pd.Series(dtype='int')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960e761-0a6d-4662-aa0c-6c99607dca29",
   "metadata": {},
   "source": [
    "## 4. Credibility Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74097d3-3573-4835-84c8-c1d6e31456a2",
   "metadata": {},
   "source": [
    "We deviate from the semantic search for a bit to create a credibility score column, based on the url (if it looks trustworthy or not).  We ask GPT-3 to do this.  Experimenting a bit (notebook with analysis should be in place, but have not done yet) it does a decent job at least in the relative aspect i.e. It gives Nature.com a 10 and homeopathy.com a 6, although the latter probably deserves a 2, but the order is still useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d1479956-5612-457c-b022-fbff177e5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Assume you are a University Profressor, experienced in researching and evaluating sources of information. \n",
    "Here is my question. I google \"{0}\" and got this link: {1} Can I trust the information on this url? \n",
    "From 1 to 10, how would you score the reputation of this source? Please only output the number.\n",
    "\"\"\"\n",
    "score_list = []\n",
    "for url in top_urls:\n",
    "    prompt = prompt_template.format(my_question, url)\n",
    "    #print(prompt)\n",
    "    gpt_response = gpt3_completion(prompt)\n",
    "    counter = 1\n",
    "    temp =0\n",
    "    # If we don't get a numeric response or number out of 1-10 range, keep trying with more temperature\n",
    "    for i in range(4):\n",
    "        if gpt_response.isnumeric()==True:\n",
    "            if int(gpt_response) in range(11):\n",
    "                score_list.append(int(gpt_response))\n",
    "                df_urls = pd.concat([df_urls,pd.DataFrame({'url': [url],'score': [int(gpt_response)]})], ignore_index=True) \n",
    "                break\n",
    "            else:\n",
    "                temp = temp + 2*counter/10\n",
    "                gpt_response = gpt3_completion(prompt, temp=temp)\n",
    "                counter = counter + 1\n",
    "                continue\n",
    "        else:\n",
    "            temp = temp + 2*counter/10\n",
    "            gpt_response = gpt3_completion(prompt, temp=temp)\n",
    "        counter = counter + 1\n",
    "        if counter == 4:\n",
    "            break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fcbcbc8a-e422-474c-91eb-930bee8958b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_urls(top_urls, df, my_question, pprint = True):\n",
    "    \"\"\"This function creates a dataframe (df_urls) of URLs and their respective trust scores.\n",
    "    Inputs: \n",
    "    top_urls (list): A list of URLs\n",
    "    df (DataFrame): A DataFrame\n",
    "    my_question (str): A string representing a question\n",
    "    pprint (bool): A boolean determining if print statements should be executed\n",
    "    Outputs:\n",
    "    df_urls (DataFrame): A DataFrame of URLs and their respective trust scores\n",
    "    \"\"\"\n",
    "    \n",
    "    df_urls = pd.DataFrame({'url': pd.Series(dtype='str'),\n",
    "                       'score': pd.Series(dtype='int')})\n",
    "    score_list = []\n",
    "    for url in top_urls:\n",
    "        prompt_template = \"\"\"Assume you are a University Profressor, experienced in researching and evaluating sources of information. \n",
    "        Here is my question. I google \"{0}\" and got this link: {1} Can I trust the information on this url? \n",
    "        From 1 to 10, how would you score the reputation of this source? Please only output the number.\n",
    "        \"\"\"\n",
    "        prompt = prompt_template.format(my_question, url)\n",
    "        #print(prompt)\n",
    "        if pprint:\n",
    "            print(url)\n",
    "            print('fetch gpt')\n",
    "        gpt_response = gpt3_completion(prompt)\n",
    "        if pprint:\n",
    "            print(gpt_response)\n",
    "        temp =0\n",
    "        # If we don't get a numeric response or number out of 1-10 range, keep trying with more temperature\n",
    "        for i in range(4):\n",
    "            if gpt_response.isnumeric()==True:\n",
    "                if int(gpt_response) in range(11):\n",
    "                    score_list.append(int(gpt_response))\n",
    "                    df_urls = pd.concat([df_urls,pd.DataFrame({'url': [url],'score': [int(gpt_response)]})], ignore_index=True) \n",
    "                    break\n",
    "                else:\n",
    "                    temp = temp + 2*i/10\n",
    "                    if pprint:\n",
    "                        print('fetch gpt on rebound')\n",
    "                    gpt_response = gpt3_completion(prompt, temp=temp)\n",
    "                    if pprint:\n",
    "                        print(gpt_response)\n",
    "                    counter = counter + 1\n",
    "                    continue\n",
    "            else:\n",
    "                temp = temp + 2*i/10\n",
    "                gpt_response = gpt3_completion(prompt, temp=temp)\n",
    "    return df_urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1afc33da-9090-4961-af94-db9ef25639f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 7, 9, 7, 8, 8, 8, 7, 8, 9]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4288a58f-f3d6-437c-9260-2623a8bbd37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.foxchase.org/blog/are-we-any-close...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.hsph.harvard.edu/magazine/magazine...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://futurism.com/neoscope/vaccine-predict-...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.worldwidecancerresearch.org/news-o...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.icr.ac.uk/blogs/science-talk/page-...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.roswellpark.org/cancertalk/201909/...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.verywellhealth.com/will-cancer-eve...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.theatlantic.com/magazine/archive/2...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.cancer.gov/news-events/cancer-curr...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  score\n",
       "0  https://ec.europa.eu/research-and-innovation/e...      8\n",
       "1  https://www.foxchase.org/blog/are-we-any-close...      7\n",
       "2  https://www.hsph.harvard.edu/magazine/magazine...      9\n",
       "3  https://futurism.com/neoscope/vaccine-predict-...      7\n",
       "4  https://www.worldwidecancerresearch.org/news-o...      8\n",
       "5  https://www.icr.ac.uk/blogs/science-talk/page-...      8\n",
       "6  https://www.roswellpark.org/cancertalk/201909/...      8\n",
       "7  https://www.verywellhealth.com/will-cancer-eve...      7\n",
       "8  https://www.theatlantic.com/magazine/archive/2...      8\n",
       "9  https://www.cancer.gov/news-events/cancer-curr...      9"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22558ec7-5998-49c5-a5be-3a87cd571fa5",
   "metadata": {},
   "source": [
    "## 5. Semantic Search with credibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ad107-c089-469e-aa0c-3b7cc732753f",
   "metadata": {},
   "source": [
    "We will now filter by credibility initially (top m urls), then find the top n similar snippets according to semantic search.  Remember, each url wil give rise to many snippets i.e. we split the text in the url's website into snippets that we can pass to GPT-3 later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae6f846e-ee2c-4966-8f1a-6e4741c6c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_snippets(my_question, df, df_urls, top_m_urls, top_n_snippets):\n",
    "    \"\"\"This function takes a question, a dataframe, a dataframe of urls, the number of top URLs, and the number of top snippets \n",
    "        as input, and returns a dataframe of the most relevant snippets as output. It first sorts the urls dataframe by score\n",
    "        and takes the top m urls. It then merges this dataframe with the original dataframe and removes any duplicated columns. \n",
    "        It then searches the dataframe for the most relevant snippets and returns a dataframe of the top n snippets.\n",
    "    \"\"\"\n",
    "    url_sorted = df_urls.sort_values(by='score', ascending=False).head(top_m_urls)\n",
    "    df = pd.merge(df,url_sorted, on='url', how='inner')\n",
    "    df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "    df = search_snippets(df, my_question, n = top_n_snippets, pprint=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f8d34e62-df4b-437c-bdf5-7bf0bcd64c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\n",
      "\n",
      "snippet_id\n",
      "\n",
      "text\n",
      "\n",
      "embedding\n",
      "\n",
      "score\n",
      "\n",
      "similarity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_df = find_snippets(my_question, df, df_urls, 4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "10102386-f284-4514-96bd-3107a8dd9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df = search_df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f68b631e-5135-4b90-9938-17cd85f7b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>2</td>\n",
       "      <td>em is stimulated to attack the cancer) has als...</td>\n",
       "      <td>[-0.007977260276675224, -0.0039186542853713036...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.684178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.hsph.harvard.edu/magazine/magazine...</td>\n",
       "      <td>1</td>\n",
       "      <td>ic predispositions. The majority of risk, the ...</td>\n",
       "      <td>[0.007141884882003069, -0.0015429595950990915,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.679147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>0</td>\n",
       "      <td>We asked three cancer experts - Nobel laureate...</td>\n",
       "      <td>[0.012988211587071419, -0.005143945105373859, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.683805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>4</td>\n",
       "      <td>shape the Horizon Europe work programme, an i...</td>\n",
       "      <td>[-0.001004464807920158, 6.958011363167316e-05,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.652864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url snippet_id  \\\n",
       "2  https://ec.europa.eu/research-and-innovation/e...          2   \n",
       "9  https://www.hsph.harvard.edu/magazine/magazine...          1   \n",
       "0  https://ec.europa.eu/research-and-innovation/e...          0   \n",
       "4  https://ec.europa.eu/research-and-innovation/e...          4   \n",
       "\n",
       "                                                text  \\\n",
       "2  em is stimulated to attack the cancer) has als...   \n",
       "9  ic predispositions. The majority of risk, the ...   \n",
       "0  We asked three cancer experts - Nobel laureate...   \n",
       "4   shape the Horizon Europe work programme, an i...   \n",
       "\n",
       "                                           embedding  score  similarity  \n",
       "2  [-0.007977260276675224, -0.0039186542853713036...      9    0.684178  \n",
       "9  [0.007141884882003069, -0.0015429595950990915,...      9    0.679147  \n",
       "0  [0.012988211587071419, -0.005143945105373859, ...      8    0.683805  \n",
       "4  [-0.001004464807920158, 6.958011363167316e-05,...      8    0.652864  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943eef7-b378-43c6-ac76-d3a78f2e5c62",
   "metadata": {},
   "source": [
    "## 6. GPT-3 Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56836d-2bec-4ee4-ab00-545650f21dd3",
   "metadata": {},
   "source": [
    "For each candidate snippet of text we ask GPT-3 to extract an answer to the question (or output \"No relevant info\" so we can filter later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45faac38-01a4-44ab-a16a-3ad908ca4ae5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gpt_answers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearch_df\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mI have a question and a paragraph.  Please extract an answer from the paragraph if present, otherwise say \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo relevant information here\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    QUESTION:\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    PARAGRAPH:\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    ANSWER:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(my_question, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     completion \u001b[38;5;241m=\u001b[39m gpt3_completion(prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search_df' is not defined"
     ]
    }
   ],
   "source": [
    "gpt_answers = []\n",
    "for index, row in search_df.iterrows():\n",
    "    prompt = \"\"\"I have a question and a paragraph.  Please extract an answer from the paragraph if present, otherwise say \"No relevant information here\"\n",
    "    QUESTION:\n",
    "    {0}\n",
    "    PARAGRAPH:\n",
    "    {1}\n",
    "    ANSWER:\"\"\".format(my_question, row['text'])\n",
    "    completion = gpt3_completion(prompt)\n",
    "    gpt_answers.append(completion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe832946-02e9-4296-956e-9ebef64d6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(search_df, my_question, pprint = True):\n",
    "    \"\"\"\n",
    "    This function takes three parameters: a search dataframe consisting of text, a question string, and a \n",
    "    boolean value for pprint. It uses a GPT-3 completion to extract an answer from each row of the search dataframe based \n",
    "    on the question string, appending the answer to the search dataframe as a new column. If the pprint parameter is set to \n",
    "    True, the prompt and answer will be printed to the console. The function returns the search \n",
    "    dataframe with the answers added.\n",
    "    \"\"\"\n",
    "    gpt_answers = []\n",
    "    for index, row in search_df.iterrows():\n",
    "        prompt = \"\"\"I have a question and a paragraph.  Please extract an answer from the paragraph if present, otherwise say \"No relevant information here\n",
    "        QUESTION:\n",
    "        {0}\n",
    "        PARAGRAPH:\n",
    "        {1}\n",
    "        ANSWER:\"\"\".format(my_question, row['text'])\n",
    "        completion = gpt3_completion(prompt)\n",
    "        gpt_answers.append(completion)\n",
    "        if pprint:\n",
    "            print(prompt)\n",
    "    search_df['answer'] = gpt_answers\n",
    "    return search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5712eb38-06cb-4e20-a87e-e50f9fb37ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df['answer'] = gpt_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "968e12ad-8b71-482c-acf7-e8eb8403415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>2</td>\n",
       "      <td>em is stimulated to attack the cancer) has als...</td>\n",
       "      <td>[-0.007977260276675224, -0.0039186542853713036...</td>\n",
       "      <td>9</td>\n",
       "      <td>It is not possible to provide an exact timelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.hsph.harvard.edu/magazine/magazine...</td>\n",
       "      <td>1</td>\n",
       "      <td>ic predispositions. The majority of risk, the ...</td>\n",
       "      <td>[0.007141884882003069, -0.0015429595950990915,...</td>\n",
       "      <td>9</td>\n",
       "      <td>It is unlikely that cancer could ever be eradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ec.europa.eu/research-and-innovation/e...</td>\n",
       "      <td>0</td>\n",
       "      <td>We asked three cancer experts - Nobel laureate...</td>\n",
       "      <td>[0.012988211587071419, -0.005143945105373859, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>It is an open question whether we can ever com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url snippet_id  \\\n",
       "2  https://ec.europa.eu/research-and-innovation/e...          2   \n",
       "9  https://www.hsph.harvard.edu/magazine/magazine...          1   \n",
       "0  https://ec.europa.eu/research-and-innovation/e...          0   \n",
       "\n",
       "                                                text  \\\n",
       "2  em is stimulated to attack the cancer) has als...   \n",
       "9  ic predispositions. The majority of risk, the ...   \n",
       "0  We asked three cancer experts - Nobel laureate...   \n",
       "\n",
       "                                           embedding  score  \\\n",
       "2  [-0.007977260276675224, -0.0039186542853713036...      9   \n",
       "9  [0.007141884882003069, -0.0015429595950990915,...      9   \n",
       "0  [0.012988211587071419, -0.005143945105373859, ...      8   \n",
       "\n",
       "                                              answer  \n",
       "2  It is not possible to provide an exact timelin...  \n",
       "9  It is unlikely that cancer could ever be eradi...  \n",
       "0  It is an open question whether we can ever com...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4d9e2-c88e-4fe1-b0ea-c4e84586dceb",
   "metadata": {},
   "source": [
    "## 7. Search Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fa498-6d90-40c8-871a-c268ef43297b",
   "metadata": {},
   "source": [
    "We put all of the above together. The following function takes your main question and some params and does the research as specified in the intro of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "85769230-6f3f-40c8-a8b9-366933dd0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to run all of the above process\n",
    "def run_search(my_question, urls_per_search, top_m_urls, top_n_snippets, pprint = True):\n",
    "    \"\"\"This function runs a search for a given question and returns the top search results and snippets, as well as \n",
    "    proposed answer by GPT-3. It takes in 4 parameters: my_question (the question to be searched for), urls_per_search\n",
    "    (the number of urls per search), top_m_urls (the top number of urls to be returned), and top_n_snippets \n",
    "    (the top number of snippets to be returned). The output is a search_df dataframe that contains the top search \n",
    "    results and snippets for the given question.\n",
    "    \"\"\"\n",
    "    search_strings = get_search_strings(my_question)\n",
    "    print(search_strings)\n",
    "    top_urls = []\n",
    "    for search in search_strings:\n",
    "        top_urls_search = get_top_urls(search, urls_per_search, pprint)\n",
    "        top_urls = top_urls_search + top_urls\n",
    "        top_urls = deduplicate_list(top_urls)\n",
    "        sleep(1)\n",
    "    print('total urls: ')\n",
    "    print(len(top_urls))\n",
    "    df = create_df(top_urls, pprint)\n",
    "    #global z # Yes, this is horrible, but helped me debug..\n",
    "    #z = df\n",
    "    print('df created with length:')\n",
    "    print(len(df))\n",
    "    df_urls = create_df_urls(top_urls, df, my_question, pprint)\n",
    "    #global a \n",
    "    #a = df_urls\n",
    "    print('df_urls done')\n",
    "    search_df = find_snippets(my_question, df, df_urls, top_m_urls, top_n_snippets)\n",
    "    #global b\n",
    "    #b = search_df\n",
    "    print('search_df-done')\n",
    "    search_df = get_answer(search_df, my_question, pprint = pprint)\n",
    "    return search_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c09345-33d8-410b-874f-93550c3ff962",
   "metadata": {},
   "source": [
    "# 8. Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af761-6656-4ec3-b955-2a30775321b1",
   "metadata": {},
   "source": [
    "Let's get info for the question \"What are the most recent breakthroughs in Menieres disease?\". Instead of the user searching and browsing each url, we should be getting back the answer to this question, synthesized by GPT-3, according to the relevant info in each website that contains a potential answer. GPT-3 initially comes up with multiple search queries to google them and fetch the corresponding urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01531ac2-64ba-472c-a476-b22c438e5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "my_question = \"What are the most recent breakthroughs in Meniere's disease\"\n",
    "urls_per_search = 15\n",
    "top_m_urls = 40\n",
    "top_n_snippets = 40\n",
    "sdf = run_search(my_question, urls_per_search, top_m_urls, top_n_snippets)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e02aec-d193-4473-955c-5051c5321747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[sdf['answer']!='No relevant information here.']#['text'][0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4e72c4c4-cfdc-48e0-8770-8a6db075b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://emedicine.medscape.com/article/1159069-overview\n",
      "SCORE:\n",
      "9\n",
      "The most recent breakthroughs in Meniere's disease include the identification of endolymphatic hydrops utilizing delayed postcontrast 3D FLAIR and fused 3D FLAIR and CISS color maps, transtympanic steroids for Mnire's Disease, Betahistine dihydrochloride in the treatment of peripheral vestibular vertigo, clinical long-term effects of Meniett pulse generator for Meniere’s disease.\n",
      "https://www.mountsinai.org/locations/center-hearing-balance/conditions/vertigo-balance-disorders/menieres-disease\n",
      "SCORE:\n",
      "9\n",
      "Low-salt diet, medications such as gentamicin injections, and cutting back on salt to help keep the inner ear fluid low are some of the most recent breakthroughs in Meniere's disease.\n",
      "https://www.tandfonline.com/doi/full/10.1080/00016489.2020.1776385\n",
      "SCORE:\n",
      "8\n",
      "Visualization of EH invivo might make a great substantial improvement in diagnose of MD.\n",
      "https://www.medscape.com/viewarticle/928652\n",
      "SCORE:\n",
      "8\n",
      "The new clinical practice guideline from the American Academy of OtolaryngologyHead and Neck Surgery Foundation (AAO-HNSF) provides evidence-based recommendations for the diagnosis and treatment of Mnire's disease, including key action statements to guide clinicians based on best available evidence in literature.\n",
      "https://www.medscape.com/viewarticle/928652\n",
      "SCORE:\n",
      "8\n",
      "Consider offering diuretics and/or betahistine for maintenance therapy to reduce symptoms or to prevent attacks, but do not prescribe positive pressure therapy. Intratympanic (IT) steroids to patients with active Mnire's disease not responsive to noninvasive treatment IT gentamicin to those with active disease not responsive\n",
      "https://www.hopkinsmedicine.org/health/conditions-and-diseases/menieres-disease\n",
      "SCORE:\n",
      "9\n",
      "Could Gene Therapy Fix Hearing and Balance Problems?\n",
      "https://www.mayoclinic.org/diseases-conditions/menieres-disease/diagnosis-treatment/drc-20374916\n",
      "SCORE:\n",
      "9\n",
      "You may be able to improve some symptoms of Meniere's disease with self-care tips, such as avoiding triggers during a vertigo attack and joining support groups.\n",
      "https://www.bmj.com/content/352/bmj.h6816\n",
      "SCORE:\n",
      "9\n",
      "The BEMED trial is, to our knowledge, the first pragmatic randomised controlled trial that specifically focuses on how betahistine prevents attacks caused by Menieres disease.\n",
      "https://uihc.org/services/menieres-disease\n",
      "SCORE:\n",
      "8\n",
      "A low-sodium diet, combined with medication to reduce fluid in the inner ear, can be an effective treatment for the vertigo caused by Meniere's disease.\n",
      "https://www.mountsinai.org/locations/center-hearing-balance/conditions/vertigo-balance-disorders/menieres-disease\n",
      "SCORE:\n",
      "9\n",
      "Vestibular nerve section is a highly effective operation that relieves vertigo attacks while preserving the hearing. In this operation, the balance nerve is isolated under the microscope and cut. The operation provides excellent relief in most patients, with minimal side effects and more than 90% of patients will have complete relief of their vertigo with preserved preoperative level hearing about 80% of time.\n",
      "https://www.frontiersin.org/articles/10.3389/fneur.2020.581527/full\n",
      "SCORE:\n",
      "9\n",
      "The most recent breakthroughs in Meniere's disease include histopathological and ultrastructural analysis of vestibular endorgans, the dissociation between results from video head impulse versus caloric testing, vertical head impulse and caloric tests being complementary but reacting opposite to hydrops associated with Meniere's Disease, as well as an International Consensus (ICON) on treatment for Mnire’s Disease.\n",
      "https://www.ncbi.nlm.nih.gov/books/NBK536955/\n",
      "SCORE:\n",
      "9\n",
      "The exact etiology of Meniere diseaseremains unclear. Different theories exist, but genetic and environmental factors play a role.[4]\n",
      "https://www.medicalnewstoday.com/articles/163888\n",
      "SCORE:\n",
      "8\n",
      "The FDA recently approved a device that can help people who have Meniere's disease.\n",
      "https://www.bmj.com/content/352/bmj.h6816\n",
      "SCORE:\n",
      "9\n",
      "Long term prophylactic treatment with betahistine dihydrochloride (at daily doses 224 mg or 348 mg) does not change the time course of vertigo episodes related to Menieres disease compared with placebo.\n",
      "https://www.frontiersin.org/articles/10.3389/fneur.2020.581527/full\n",
      "SCORE:\n",
      "9\n",
      "The most recent breakthroughs in Meniere's disease include enhanced vestibulo-ocular reflex responses on vHIT, evidence of large vestibulo-ocular reflex reduction in patients with Menire attacks, high frequency horizontal semicircular canal function and a clinical sign of canal paresis.\n",
      "https://www.nhs.uk/conditions/menieres-disease/\n",
      "SCORE:\n",
      "9\n",
      "Betahistine is a medicine that may help reduce the frequency and severity of attacks of Meniere's disease.\n",
      "https://emedicine.medscape.com/article/1159069-overview\n",
      "SCORE:\n",
      "9\n",
      "Clinical Practice Guideline: Mnire's Disease Executive Summary. Otolaryngol Head Neck Surg. 2020 Apr. 162 (4):415-434\n"
     ]
    }
   ],
   "source": [
    "for index, row in sdf[sdf['answer']!='No relevant information here.'].iterrows():\n",
    "    print(row['url'])\n",
    "    print('SCORE:')\n",
    "    print(row['score'])\n",
    "    print(row['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adf2d2-a073-48dc-ab84-3e45d6704944",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c249836-1554-479e-83a2-6f1375954a87",
   "metadata": {},
   "source": [
    "Let's look for AI music products, this works reasonably well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ac5d97ad-d344-4a8f-adc3-95f248df3eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best AI music models commercially available', 'latest AI music models for users', 'AI-generated musical compositions', 'music composition with artificial intelligence technology ', 'commercial applications of machine learning in music production and composition ', 'artificial neural networks for automated song generation ', 'machine learning algorithms to create original songs from scratch', 'deep learning techniques used in creating new pieces of artful melodies', 'AI tools that generate unique tunes based on user input']\n",
      "total urls: \n",
      "113\n",
      "df created with length:\n",
      "613\n",
      "df_urls done\n",
      "url\n",
      "\n",
      "snippet_id\n",
      "\n",
      "text\n",
      "\n",
      "embedding\n",
      "\n",
      "score\n",
      "\n",
      "similarity\n",
      "\n",
      "search_df-done\n",
      "297.09651803970337\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "my_question = \"What is the best and latest AI music models that are commercially available for users? i.e. models that can compose music.\"\n",
    "urls_per_search = 15\n",
    "top_m_urls = 40\n",
    "top_n_snippets = 40\n",
    "sdf = run_search(my_question, urls_per_search, top_m_urls, top_n_snippets)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b4bb3cb8-70a7-4f9d-a274-023f38a3be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_df_urls(top_urls, df, my_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3c558b91-7d73-4696-a1cd-b57d93a22bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf[sdf['answer']!='No relevant information here.']#['text'][0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "99a90d96-3c37-4522-af1d-36a97feeef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.xyonix.com/blog/how-ai-is-transforming-music-composition\n",
      "SCORE:\n",
      "7\n",
      "OpenAI's Jukebox, which uses a Vector Quantized Variational AutoEncoder (VQ-VAE) to downsample original audio from the standard sampling rate of 44.1kHz down to 344Hz and then composes new songs based on compressed audio files.\n",
      "https://ai.stackexchange.com/questions/7734/what-are-the-best-machine-learning-models-for-music-composition\n",
      "SCORE:\n",
      "8\n",
      "The most recent AI music model commercially available is from DeepMind: The challenge of realistic music generation: modelling raw audio at scale.\n",
      "https://www.xyonix.com/blog/how-ai-is-transforming-music-composition\n",
      "SCORE:\n",
      "7\n",
      "Artificial Intelligence Virtual Artist (AIVA)\n",
      "https://www.loudly.com/artificial-intelligence-music-composer\n",
      "SCORE:\n",
      "7\n",
      "Experiments in Music Intelligence (EMI)\n",
      "https://filmora.wondershare.com/audio-editing/best-ai-music-composer.html\n",
      "SCORE:\n",
      "7\n",
      "Amper Music, AIVA Technologies and Jukedeck are three of the best AI music models that are commercially available for users.\n",
      "https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music\n",
      "SCORE:\n",
      "7\n",
      "Amper Music, Flow Machines, IBM Watson Beat, Google Magentas NSynth Super, Jukedeck, Melodrive , Spotifys Creator Technology Research Lab.\n",
      "https://medium.com/syncedreview/ais-growing-role-in-musical-composition-ec105417899\n",
      "SCORE:\n",
      "8\n",
      "Amper Music and Aiva are two commercially available AI music models that can compose music.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "Amper Music, AIVA, IBM Watson Music and Magenta are some of the best and latest AI music models that are commercially available for users.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "AIVA is currently only being used to compose classical pieces of music, but its creators are looking to expand its output and allow for the AIVA program to compose music in any style.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "Google Magenta, IBM Watson Beat\n",
      "https://futurism.com/a-new-ai-can-write-music-as-well-as-a-human-composer\n",
      "SCORE:\n",
      "7\n",
      "Aiva Technologies is one of the leading startups in the field of AI music composition and has created an AI called Aiva (Artificial Intelligence Virtual Artist) which can compose classical music. It was registered under France and Luxembourg authors right society (SACEM), where all its works reside with a copyright to its own name.\n",
      "https://blog.bpmmusic.io/news/the-future-of-ai-and-music-production/\n",
      "SCORE:\n",
      "7\n",
      "Amadeus Code, Magenta by Google Labs, Orb Producer Pack, Neutron and Ozone (by Izotope), LANDR and Emastered.\n",
      "https://medium.com/syncedreview/ais-growing-role-in-musical-composition-ec105417899\n",
      "SCORE:\n",
      "8\n",
      "IBM's Watson Beat and Aiva Technologies' AI app Aiva (Artificial Intelligence Virtual Artist) are the best and latest commercially available AI music models that can compose music.\n",
      "https://www.musicradar.com/news/composing-with-artificial-intelligence\n",
      "SCORE:\n",
      "7\n",
      "Orb Producer Suite and Hookpad are two commercially available AI music models that can compose music.\n",
      "https://www.musicradar.com/news/composing-with-artificial-intelligence\n",
      "SCORE:\n",
      "7\n",
      "Aiva, Amper and Ecrett Music are some of the best and latest AI music models that are commercially available for users.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "Lost Tapes of the 27 Club's AI technology is one example of a commercially available model that can compose music.\n",
      "https://www.musicradar.com/news/composing-with-artificial-intelligence\n",
      "SCORE:\n",
      "7\n",
      "Ecrett Music, Soundraw, Aiva, Amper Music and Humtap are the best and latest AI music models that are commercially available for users.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "AIVA is slightly better due to its music quality and free download feature.\n",
      "https://amt-lab.org/blog/2021/10/can-computers-be-creative-a-look-at-ai-use-in-music-composition\n",
      "SCORE:\n",
      "8\n",
      "Google Magenta, IBM Watson Beat, Amper Music and AIVA are some of the best and latest AI music models that are commercially available for users.\n",
      "https://transactions.ismir.net/articles/10.5334/tismir.100/\n",
      "SCORE:\n",
      "8\n",
      "Yang et al. (2017); Payne (2019); Hadjeres et al. (2017); Hadjeres and Crestel (2021); Roberts et al. (2019)\n",
      "https://transactions.ismir.net/articles/10.5334/tismir.100/\n",
      "SCORE:\n",
      "8\n",
      "Dhariwal et al., 2020\n",
      "https://www.hindawi.com/journals/mpe/2022/2138059/\n",
      "SCORE:\n",
      "7\n",
      "Magenta Studio, an AI composition tool from Google\n",
      "https://www.nbcnews.com/mach/science/ai-can-now-compose-pop-music-even-symphonies-here-s-ncna1010931\n",
      "SCORE:\n",
      "8\n",
      "Google's Magenta, Sony's Flow Machines and Jukedeck are some of the best and latest AI music models that are commercially available for users.\n",
      "https://blog.bpmmusic.io/news/the-future-of-ai-and-music-production/\n",
      "SCORE:\n",
      "7\n",
      "Amper and AIVA are two of the earliest AI music models that are commercially available for users.\n",
      "https://www.nbcnews.com/mach/science/ai-can-now-compose-pop-music-even-symphonies-here-s-ncna1010931\n",
      "SCORE:\n",
      "8\n",
      "Southern, the Los Angeles-based pop artist, says AI technology is perfect for someone like her: a music lover who grew up writing code but who lacks formal training in either discipline.\n",
      "https://transactions.ismir.net/articles/10.5334/tismir.100/\n",
      "SCORE:\n",
      "8\n",
      "Magenta Studio (Roberts et al., 2019), DeepBach (Hadjeres et al., 2017), and the Piano Inpainting Application (Hadjeres and Crestel, 2021).\n"
     ]
    }
   ],
   "source": [
    "for index, row in sdf[sdf['answer']!='No relevant information here.'].iterrows():\n",
    "    print(row['url'])\n",
    "    print('SCORE:')\n",
    "    print(row['score'])\n",
    "    print(row['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749556d-a0ac-473d-8cf6-6492e9652547",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aac119-3779-4816-8745-9d530a4061e2",
   "metadata": {},
   "source": [
    "The first ones were quite good.  The following is probably more complicated, since there might not be much information out there.\n",
    "The question is \"Will audioLM, the AI model for music continuation, be put into a product?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69211aa1-d114-497f-bfed-1fbb86797f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "my_question = \"Will audioLM, the AI model for music continuation, be put into a product?\"\n",
    "urls_per_search = 10 # How many urls to fetch from each google search, so total urls =this*number_of_proposed_searches_by_gpt3 minus any duplication\n",
    "top_m_urls = 15 # Once scored by credibility, how many to keep\n",
    "top_n_snippets = 25 # many snippets per url. How many to send to gpt3 as candidates for containing answer\n",
    "sdf = run_search(my_question, urls_per_search, top_m_urls, top_n_snippets)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73a168c4-4413-4ac5-9b91-0e0155508072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.lenseup.com/en/google-audio-lm-is-already-capable-of-making-speeches-with-your-voice/\n",
      "SCORE:\n",
      "7\n",
      "For the moment AudioLM is not open to the public, it is only a language model that can be integrated into different projects.\n"
     ]
    }
   ],
   "source": [
    "for index, row in sdf[sdf['answer']!='No relevant information here.'].iterrows():\n",
    "    print(row['url'])\n",
    "    print('SCORE:')\n",
    "    print(row['score'])\n",
    "    print(row['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42f05981-521f-48da-8758-7b562c16d4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "      <th>similarity</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.technologyreview.com/2022/10/07/10...</td>\n",
       "      <td>0</td>\n",
       "      <td>The technique, called AudioLM, generates natur...</td>\n",
       "      <td>[-0.018406299874186516, -0.002623820910230279,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.869921</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.automationalley.com/articles/googl...</td>\n",
       "      <td>0</td>\n",
       "      <td>The technique, called AudioLM, generates natur...</td>\n",
       "      <td>[-0.013355117291212082, -0.027182146906852722,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.lenseup.com/en/google-audio-lm-is-...</td>\n",
       "      <td>0</td>\n",
       "      <td>Computers are already able to play chess games...</td>\n",
       "      <td>[-0.009313440881669521, -0.008414073847234249,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.866068</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.technologyreview.com/2022/10/07/10...</td>\n",
       "      <td>1</td>\n",
       "      <td>when piano keys are struck. The music also ha...</td>\n",
       "      <td>[-0.0166457649320364, 0.002376771531999111, 0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.858494</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://musically.com/2022/10/10/google-harmon...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nUsername or Email Address\\n\\n\\nPassword\\n\\n ...</td>\n",
       "      <td>[-0.017838450148701668, -0.012966717593371868,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855964</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ai.googleblog.com/2022/10/audiolm-lang...</td>\n",
       "      <td>2</td>\n",
       "      <td>We release more samples on this webpage.\\n\\nT...</td>\n",
       "      <td>[-0.013859458267688751, -0.005921768490225077,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.855810</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.lenseup.com/en/google-audio-lm-is-...</td>\n",
       "      <td>1</td>\n",
       "      <td>artificial intelligence is not that it is abl...</td>\n",
       "      <td>[-0.01638486608862877, -0.016690753400325775, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.846960</td>\n",
       "      <td>For the moment AudioLM is not open to the publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.analyticsinsight.net/the-ais-new-w...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nAnalytics Insight\\nLinux vs Windows: Which O...</td>\n",
       "      <td>[-0.00034020928433164954, -0.01493803132325410...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.845151</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.analyticsinsight.net/the-ais-new-w...</td>\n",
       "      <td>1</td>\n",
       "      <td>nerative Pre-trained Transformer 3 (GPT-3) pre...</td>\n",
       "      <td>[-0.007595139089971781, -0.015444154851138592,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.839728</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ai.googleblog.com/2022/10/audiolm-lang...</td>\n",
       "      <td>1</td>\n",
       "      <td>racted from w2v-BERT, a self-supervised audio ...</td>\n",
       "      <td>[-0.013595780357718468, 0.004617499187588692, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.834435</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ai.googleblog.com/2022/10/audiolm-lang...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nGenerating realistic audio requires modeling...</td>\n",
       "      <td>[-0.021401889622211456, 0.009736050851643085, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://openai.com/blog/jukebox/</td>\n",
       "      <td>3</td>\n",
       "      <td>e also slow to sample from, because of the aut...</td>\n",
       "      <td>[-0.026122108101844788, -0.02807319536805153, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.820603</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://openai.com/blog/jukebox/</td>\n",
       "      <td>0</td>\n",
       "      <td>We’re introducing Jukebox, a neural net that g...</td>\n",
       "      <td>[-0.02663913182914257, -0.023703280836343765, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://musically.com/2022/10/10/google-harmon...</td>\n",
       "      <td>1</td>\n",
       "      <td>e method here is opt-in only and we look forwa...</td>\n",
       "      <td>[-0.018474973738193512, -0.039262805134058, 0....</td>\n",
       "      <td>7</td>\n",
       "      <td>0.814028</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.technologyreview.com/2022/10/07/10...</td>\n",
       "      <td>2</td>\n",
       "      <td>the paper, the researchers write that they are...</td>\n",
       "      <td>[-0.008494654670357704, -0.01149937603622675, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.808187</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://openai.com/blog/musenet/</td>\n",
       "      <td>2</td>\n",
       "      <td>given the same timing embedding. We then add a...</td>\n",
       "      <td>[-0.02336846850812435, -0.012177933938801289, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800543</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://openai.com/blog/musenet/</td>\n",
       "      <td>0</td>\n",
       "      <td>We've created MuseNet, a deep neural network t...</td>\n",
       "      <td>[-0.03164071589708328, -0.008458545431494713, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.797365</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://openai.com/blog/musenet/</td>\n",
       "      <td>1</td>\n",
       "      <td>a piece, like in the following sample imitatin...</td>\n",
       "      <td>[-0.03205038979649544, 0.003180257510393858, 0...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.786777</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://openai.com/blog/jukebox/</td>\n",
       "      <td>1</td>\n",
       "      <td>ir approach to music. We modify their architec...</td>\n",
       "      <td>[-0.004817558918148279, -0.005963301286101341,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.786659</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://openai.com/blog/jukebox/</td>\n",
       "      <td>2</td>\n",
       "      <td>ing.This t-SNE below shows how the model learn...</td>\n",
       "      <td>[-0.027380699291825294, -0.01426078099757433, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.782468</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://azure.microsoft.com/en-us/products/mac...</td>\n",
       "      <td>13</td>\n",
       "      <td>cus more on data science and let Azure Machine...</td>\n",
       "      <td>[-0.04412194713950157, -0.009324529208242893, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.776597</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://azure.microsoft.com/en-us/products/mac...</td>\n",
       "      <td>12</td>\n",
       "      <td>es at scale.See why Forrester named Azure Mach...</td>\n",
       "      <td>[-0.026593059301376343, -0.021969957277178764,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.768448</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://azure.microsoft.com/en-us/products/mac...</td>\n",
       "      <td>10</td>\n",
       "      <td>powerful cloud-based CPU and GPU clusters.Str...</td>\n",
       "      <td>[-0.021870313212275505, -0.0123819625005126, 0...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.764533</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://azure.microsoft.com/en-us/products/mac...</td>\n",
       "      <td>9</td>\n",
       "      <td>nability, and responsible usage for compliance...</td>\n",
       "      <td>[-0.010684222914278507, -0.01685086265206337, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.764121</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://azure.microsoft.com/en-us/products/mac...</td>\n",
       "      <td>8</td>\n",
       "      <td>ild, quickly launch, and reliably scale your g...</td>\n",
       "      <td>[-0.016398604959249496, -0.02092890627682209, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.759676</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url snippet_id  \\\n",
       "17  https://www.technologyreview.com/2022/10/07/10...          0   \n",
       "24  https://www.automationalley.com/articles/googl...          0   \n",
       "22  https://www.lenseup.com/en/google-audio-lm-is-...          0   \n",
       "18  https://www.technologyreview.com/2022/10/07/10...          1   \n",
       "25  https://musically.com/2022/10/10/google-harmon...          0   \n",
       "2   https://ai.googleblog.com/2022/10/audiolm-lang...          2   \n",
       "23  https://www.lenseup.com/en/google-audio-lm-is-...          1   \n",
       "27  https://www.analyticsinsight.net/the-ais-new-w...          0   \n",
       "28  https://www.analyticsinsight.net/the-ais-new-w...          1   \n",
       "1   https://ai.googleblog.com/2022/10/audiolm-lang...          1   \n",
       "0   https://ai.googleblog.com/2022/10/audiolm-lang...          0   \n",
       "34                   https://openai.com/blog/jukebox/          3   \n",
       "31                   https://openai.com/blog/jukebox/          0   \n",
       "26  https://musically.com/2022/10/10/google-harmon...          1   \n",
       "19  https://www.technologyreview.com/2022/10/07/10...          2   \n",
       "37                   https://openai.com/blog/musenet/          2   \n",
       "35                   https://openai.com/blog/musenet/          0   \n",
       "36                   https://openai.com/blog/musenet/          1   \n",
       "32                   https://openai.com/blog/jukebox/          1   \n",
       "33                   https://openai.com/blog/jukebox/          2   \n",
       "16  https://azure.microsoft.com/en-us/products/mac...         13   \n",
       "15  https://azure.microsoft.com/en-us/products/mac...         12   \n",
       "13  https://azure.microsoft.com/en-us/products/mac...         10   \n",
       "12  https://azure.microsoft.com/en-us/products/mac...          9   \n",
       "11  https://azure.microsoft.com/en-us/products/mac...          8   \n",
       "\n",
       "                                                 text  \\\n",
       "17  The technique, called AudioLM, generates natur...   \n",
       "24  The technique, called AudioLM, generates natur...   \n",
       "22  Computers are already able to play chess games...   \n",
       "18   when piano keys are struck. The music also ha...   \n",
       "25  \\nUsername or Email Address\\n\\n\\nPassword\\n\\n ...   \n",
       "2    We release more samples on this webpage.\\n\\nT...   \n",
       "23   artificial intelligence is not that it is abl...   \n",
       "27  \\nAnalytics Insight\\nLinux vs Windows: Which O...   \n",
       "28  nerative Pre-trained Transformer 3 (GPT-3) pre...   \n",
       "1   racted from w2v-BERT, a self-supervised audio ...   \n",
       "0   \\nGenerating realistic audio requires modeling...   \n",
       "34  e also slow to sample from, because of the aut...   \n",
       "31  We’re introducing Jukebox, a neural net that g...   \n",
       "26  e method here is opt-in only and we look forwa...   \n",
       "19  the paper, the researchers write that they are...   \n",
       "37  given the same timing embedding. We then add a...   \n",
       "35  We've created MuseNet, a deep neural network t...   \n",
       "36  a piece, like in the following sample imitatin...   \n",
       "32  ir approach to music. We modify their architec...   \n",
       "33  ing.This t-SNE below shows how the model learn...   \n",
       "16  cus more on data science and let Azure Machine...   \n",
       "15  es at scale.See why Forrester named Azure Mach...   \n",
       "13   powerful cloud-based CPU and GPU clusters.Str...   \n",
       "12  nability, and responsible usage for compliance...   \n",
       "11  ild, quickly launch, and reliably scale your g...   \n",
       "\n",
       "                                            embedding  score  similarity  \\\n",
       "17  [-0.018406299874186516, -0.002623820910230279,...      8    0.869921   \n",
       "24  [-0.013355117291212082, -0.027182146906852722,...      7    0.866200   \n",
       "22  [-0.009313440881669521, -0.008414073847234249,...      7    0.866068   \n",
       "18  [-0.0166457649320364, 0.002376771531999111, 0....      8    0.858494   \n",
       "25  [-0.017838450148701668, -0.012966717593371868,...      7    0.855964   \n",
       "2   [-0.013859458267688751, -0.005921768490225077,...      9    0.855810   \n",
       "23  [-0.01638486608862877, -0.016690753400325775, ...      7    0.846960   \n",
       "27  [-0.00034020928433164954, -0.01493803132325410...      7    0.845151   \n",
       "28  [-0.007595139089971781, -0.015444154851138592,...      7    0.839728   \n",
       "1   [-0.013595780357718468, 0.004617499187588692, ...      9    0.834435   \n",
       "0   [-0.021401889622211456, 0.009736050851643085, ...      9    0.828500   \n",
       "34  [-0.026122108101844788, -0.02807319536805153, ...      9    0.820603   \n",
       "31  [-0.02663913182914257, -0.023703280836343765, ...      9    0.815596   \n",
       "26  [-0.018474973738193512, -0.039262805134058, 0....      7    0.814028   \n",
       "19  [-0.008494654670357704, -0.01149937603622675, ...      8    0.808187   \n",
       "37  [-0.02336846850812435, -0.012177933938801289, ...      9    0.800543   \n",
       "35  [-0.03164071589708328, -0.008458545431494713, ...      9    0.797365   \n",
       "36  [-0.03205038979649544, 0.003180257510393858, 0...      9    0.786777   \n",
       "32  [-0.004817558918148279, -0.005963301286101341,...      9    0.786659   \n",
       "33  [-0.027380699291825294, -0.01426078099757433, ...      9    0.782468   \n",
       "16  [-0.04412194713950157, -0.009324529208242893, ...      8    0.776597   \n",
       "15  [-0.026593059301376343, -0.021969957277178764,...      8    0.768448   \n",
       "13  [-0.021870313212275505, -0.0123819625005126, 0...      8    0.764533   \n",
       "12  [-0.010684222914278507, -0.01685086265206337, ...      8    0.764121   \n",
       "11  [-0.016398604959249496, -0.02092890627682209, ...      8    0.759676   \n",
       "\n",
       "                                               answer  \n",
       "17                      No relevant information here.  \n",
       "24                      No relevant information here.  \n",
       "22                      No relevant information here.  \n",
       "18                      No relevant information here.  \n",
       "25                      No relevant information here.  \n",
       "2                       No relevant information here.  \n",
       "23  For the moment AudioLM is not open to the publ...  \n",
       "27                      No relevant information here.  \n",
       "28                      No relevant information here.  \n",
       "1                       No relevant information here.  \n",
       "0                       No relevant information here.  \n",
       "34                      No relevant information here.  \n",
       "31                      No relevant information here.  \n",
       "26                      No relevant information here.  \n",
       "19                      No relevant information here.  \n",
       "37                      No relevant information here.  \n",
       "35                      No relevant information here.  \n",
       "36                      No relevant information here.  \n",
       "32                      No relevant information here.  \n",
       "33                      No relevant information here.  \n",
       "16                      No relevant information here.  \n",
       "15                      No relevant information here.  \n",
       "13                      No relevant information here.  \n",
       "12                      No relevant information here.  \n",
       "11                      No relevant information here.  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf\n",
    "# There seem to be many urls for which there is no relevant information in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3636a-e5df-4343-950a-fc0c1db31234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_response = (\n",
    "    sdf.sort_values(\"score\", ascending=False)\n",
    "    .head(n)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72eab23-4e13-471c-a082-d9d7ab1eb419",
   "metadata": {},
   "source": [
    "# Example 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4b0d2-f998-4a5f-a090-8175ad9c36dd",
   "metadata": {},
   "source": [
    "Last example was not great.. This one is more controversial, the question is \"Was COVID caused by a lab leak?\".  We surprisingly get no answers extracted by GPT-3, even though there is information there.. Maybe some safety mechanism kicked in. I tried with the following prompt and got \"No relevant information here\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da39412-f182-4064-a6ad-85022e8cda26",
   "metadata": {},
   "source": [
    "##### I have a question and a paragraph.  Please extract an answer from the paragraph if present, otherwise say \"No relevant information here\"\n",
    "#####    QUESTION:\n",
    "#####    Was COVID caused by a lab leak?\n",
    "#####    PARAGRAPH:\n",
    "#####    There was a lab leak in Wuhan and the virus came from there.\n",
    "#####    ANSWER: No relevant information here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe20e42-b7de-4cf2-850f-f0b237c5bcf8",
   "metadata": {},
   "source": [
    "On the other hand if I specified \"COVID virus\", then it outputs \"Yes\". Not sure what is happening here, but could be looked into further if this kind of behaviour shows up often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "998e8409-ea9d-4f8e-933a-860e032127cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID lab leak evidence', 'Was COVID caused by a laboratory accident?', 'Scientific research on the origin of COVID-19', 'Did SARS-CoV2 originate in a lab?', 'Is there proof that coronavirus was created in a laboratory?', 'Evidence for and against the theory of Covid 19 originating from Wuhan Lab', \"Does scientific data support claims about covid's origins?\", 'What is known about potential sources of 2019 novel Coronavirus (2019nCov) infection? ', 'Are scientists certain where Covid originated from?', 'Research into whether or not COVID came from an animal source']\n",
      "total urls: \n",
      "68\n",
      "df created with length:\n",
      "381\n",
      "df_urls done\n",
      "url\n",
      "\n",
      "snippet_id\n",
      "\n",
      "text\n",
      "\n",
      "embedding\n",
      "\n",
      "score\n",
      "\n",
      "similarity\n",
      "\n",
      "search_df-done\n",
      "201.50075340270996\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "my_question = \"Was COVID caused by a lab leak?\"\n",
    "urls_per_search = 10 # How many urls to fetch from each google search, so total urls =this*number_of_proposed_searches_by_gpt3 minus any duplication\n",
    "top_m_urls = 15 # Once scored by credibility, how many to keep\n",
    "top_n_snippets = 25 # many snippets per url. How many to send to gpt3 as candidates for containing answer\n",
    "sdf = run_search(my_question, urls_per_search, top_m_urls, top_n_snippets, pprint = False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48ae91cc-8b37-44b0-8f1e-35fa81b6b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sdf[sdf['answer']!='No relevant information here.'].iterrows():\n",
    "    print(row['url'])\n",
    "    print('SCORE:')\n",
    "    print(row['score'])\n",
    "    print(row['text'])\n",
    "    print(row['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ef7d8f7-c601-4f06-9710-7c0f91d04c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>score</th>\n",
       "      <th>similarity</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>https://www.cidrap.umn.edu/covid-19/scientists...</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID-19 virus, highly magnified., NIAIDSince ...</td>\n",
       "      <td>[-0.003664524294435978, -0.011543416418135166,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.871554</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://www.cfr.org/backgrounder/will-world-ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>ly viewed as implausible. In the first weeks o...</td>\n",
       "      <td>[0.006211551371961832, -0.016655869781970978, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866936</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-015...</td>\n",
       "      <td>1</td>\n",
       "      <td>emergencies at the WHO, asked for less politi...</td>\n",
       "      <td>[0.012558558024466038, -0.0007459056214429438,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.863793</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>https://www.newyorker.com/science/elements/the...</td>\n",
       "      <td>15</td>\n",
       "      <td>DARPA grant. When Jon Cohen, a writer for Sci...</td>\n",
       "      <td>[-0.004357331898063421, -0.010118323378264904,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.851911</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-015...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you for visiting nature.com. You are usi...</td>\n",
       "      <td>[0.010364314541220665, -0.007895675487816334, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.848590</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-003...</td>\n",
       "      <td>2</td>\n",
       "      <td>robiologist at the University of Manitoba in W...</td>\n",
       "      <td>[0.010820635594427586, -0.017626848071813583, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.846242</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://www.nature.com/articles/d41586-022-007...</td>\n",
       "      <td>1</td>\n",
       "      <td>sts say that they, too, would like to see more...</td>\n",
       "      <td>[-0.0007520264480262995, 0.0022817824501544237...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.845890</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://www.newyorker.com/science/elements/the...</td>\n",
       "      <td>3</td>\n",
       "      <td>ing for an origins investigation that took the...</td>\n",
       "      <td>[-0.003812673268839717, -0.014424169436097145,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.841592</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-015...</td>\n",
       "      <td>6</td>\n",
       "      <td>, Zhao Lijian, said that US labs should instea...</td>\n",
       "      <td>[0.0007590571185573936, -0.007768488489091396,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.838170</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>https://www.newyorker.com/science/elements/the...</td>\n",
       "      <td>2</td>\n",
       "      <td>ed that SARS-CoV-2 was engineered with genetic...</td>\n",
       "      <td>[0.0024028965272009373, -0.013563762418925762,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.837807</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>2</td>\n",
       "      <td>s visit to Wuhan, the disease detectives have ...</td>\n",
       "      <td>[-5.629689621855505e-05, -0.013268300332129002...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.830404</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>12</td>\n",
       "      <td>elped it spread far and wide, and signed the S...</td>\n",
       "      <td>[-3.19984283123631e-05, -0.01204727403819561, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.830207</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://www.nature.com/articles/d41586-022-007...</td>\n",
       "      <td>4</td>\n",
       "      <td>en genetically engineered. The lack of evidenc...</td>\n",
       "      <td>[0.007092211861163378, -0.020531129091978073, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.829974</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://www.cfr.org/backgrounder/will-world-ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n            Climate Change\\n          \\nGl...</td>\n",
       "      <td>[0.005820663180202246, -0.026005927473306656, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828496</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>18</td>\n",
       "      <td>cable did not appear to focus on any specific ...</td>\n",
       "      <td>[-0.0025629678275436163, -0.026948552578687668...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.827070</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>21</td>\n",
       "      <td>c. Many scientists in the West are dismayed by...</td>\n",
       "      <td>[-0.00697443587705493, -0.002737079979851842, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.nature.com/articles/d41586-022-005...</td>\n",
       "      <td>3</td>\n",
       "      <td>og in a metal cage, stacked above crates of po...</td>\n",
       "      <td>[0.014130823314189911, -0.022022755816578865, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>https://www.newyorker.com/science/elements/the...</td>\n",
       "      <td>8</td>\n",
       "      <td>on research, and so did not violate the Obama-...</td>\n",
       "      <td>[-0.004884935915470123, -0.020655907690525055,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825517</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>17</td>\n",
       "      <td>e-art laboratories such as the Wuhan institute...</td>\n",
       "      <td>[-0.004788630176335573, -0.019712286069989204,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825159</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-015...</td>\n",
       "      <td>5</td>\n",
       "      <td>ey were able to get whole or partial genomic s...</td>\n",
       "      <td>[-0.00032217783154919744, -0.03402600064873695...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>19</td>\n",
       "      <td>among some. Filippa Lentzos, a biosecurity ex...</td>\n",
       "      <td>[-0.0063687595538794994, -0.006055430509150028...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823356</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://www.nature.com/articles/d41586-021-015...</td>\n",
       "      <td>2</td>\n",
       "      <td>currently no clear evidence to back these scen...</td>\n",
       "      <td>[0.01376290526241064, -0.018722163513302803, -...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.823351</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>https://www.technologyreview.com/2022/02/09/10...</td>\n",
       "      <td>1</td>\n",
       "      <td>e. One of its labs, led by virologist Shi Zhen...</td>\n",
       "      <td>[-0.0002861587272491306, -0.021342789754271507...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.821715</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>https://www.cidrap.umn.edu/covid-19/scientists...</td>\n",
       "      <td>2</td>\n",
       "      <td>, has extensively published the genetic sequen...</td>\n",
       "      <td>[0.0020415757317095995, -0.015265116468071938,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.821227</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>https://www.cfr.org/backgrounder/will-world-ev...</td>\n",
       "      <td>2</td>\n",
       "      <td>report, the group stated that natural zoonotic...</td>\n",
       "      <td>[0.011701255105435848, -0.029144732281565666, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.820909</td>\n",
       "      <td>No relevant information here.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url snippet_id  \\\n",
       "90   https://www.cidrap.umn.edu/covid-19/scientists...          0   \n",
       "67   https://www.cfr.org/backgrounder/will-world-ev...          1   \n",
       "46   https://www.nature.com/articles/d41586-021-015...          1   \n",
       "87   https://www.newyorker.com/science/elements/the...         15   \n",
       "45   https://www.nature.com/articles/d41586-021-015...          0   \n",
       "33   https://www.nature.com/articles/d41586-021-003...          2   \n",
       "37   https://www.nature.com/articles/d41586-022-007...          1   \n",
       "75   https://www.newyorker.com/science/elements/the...          3   \n",
       "51   https://www.nature.com/articles/d41586-021-015...          6   \n",
       "74   https://www.newyorker.com/science/elements/the...          2   \n",
       "98   https://www.technologyreview.com/2022/02/09/10...          2   \n",
       "108  https://www.technologyreview.com/2022/02/09/10...         12   \n",
       "40   https://www.nature.com/articles/d41586-022-007...          4   \n",
       "66   https://www.cfr.org/backgrounder/will-world-ev...          0   \n",
       "114  https://www.technologyreview.com/2022/02/09/10...         18   \n",
       "117  https://www.technologyreview.com/2022/02/09/10...         21   \n",
       "28   https://www.nature.com/articles/d41586-022-005...          3   \n",
       "80   https://www.newyorker.com/science/elements/the...          8   \n",
       "113  https://www.technologyreview.com/2022/02/09/10...         17   \n",
       "50   https://www.nature.com/articles/d41586-021-015...          5   \n",
       "115  https://www.technologyreview.com/2022/02/09/10...         19   \n",
       "47   https://www.nature.com/articles/d41586-021-015...          2   \n",
       "97   https://www.technologyreview.com/2022/02/09/10...          1   \n",
       "92   https://www.cidrap.umn.edu/covid-19/scientists...          2   \n",
       "68   https://www.cfr.org/backgrounder/will-world-ev...          2   \n",
       "\n",
       "                                                  text  \\\n",
       "90   COVID-19 virus, highly magnified., NIAIDSince ...   \n",
       "67   ly viewed as implausible. In the first weeks o...   \n",
       "46    emergencies at the WHO, asked for less politi...   \n",
       "87    DARPA grant. When Jon Cohen, a writer for Sci...   \n",
       "45   Thank you for visiting nature.com. You are usi...   \n",
       "33   robiologist at the University of Manitoba in W...   \n",
       "37   sts say that they, too, would like to see more...   \n",
       "75   ing for an origins investigation that took the...   \n",
       "51   , Zhao Lijian, said that US labs should instea...   \n",
       "74   ed that SARS-CoV-2 was engineered with genetic...   \n",
       "98   s visit to Wuhan, the disease detectives have ...   \n",
       "108  elped it spread far and wide, and signed the S...   \n",
       "40   en genetically engineered. The lack of evidenc...   \n",
       "66   \\n\\n            Climate Change\\n          \\nGl...   \n",
       "114  cable did not appear to focus on any specific ...   \n",
       "117  c. Many scientists in the West are dismayed by...   \n",
       "28   og in a metal cage, stacked above crates of po...   \n",
       "80   on research, and so did not violate the Obama-...   \n",
       "113  e-art laboratories such as the Wuhan institute...   \n",
       "50   ey were able to get whole or partial genomic s...   \n",
       "115   among some. Filippa Lentzos, a biosecurity ex...   \n",
       "47   currently no clear evidence to back these scen...   \n",
       "97   e. One of its labs, led by virologist Shi Zhen...   \n",
       "92   , has extensively published the genetic sequen...   \n",
       "68   report, the group stated that natural zoonotic...   \n",
       "\n",
       "                                             embedding  score  similarity  \\\n",
       "90   [-0.003664524294435978, -0.011543416418135166,...      9    0.871554   \n",
       "67   [0.006211551371961832, -0.016655869781970978, ...      8    0.866936   \n",
       "46   [0.012558558024466038, -0.0007459056214429438,...      9    0.863793   \n",
       "87   [-0.004357331898063421, -0.010118323378264904,...      8    0.851911   \n",
       "45   [0.010364314541220665, -0.007895675487816334, ...      9    0.848590   \n",
       "33   [0.010820635594427586, -0.017626848071813583, ...      9    0.846242   \n",
       "37   [-0.0007520264480262995, 0.0022817824501544237...      9    0.845890   \n",
       "75   [-0.003812673268839717, -0.014424169436097145,...      8    0.841592   \n",
       "51   [0.0007590571185573936, -0.007768488489091396,...      9    0.838170   \n",
       "74   [0.0024028965272009373, -0.013563762418925762,...      8    0.837807   \n",
       "98   [-5.629689621855505e-05, -0.013268300332129002...      8    0.830404   \n",
       "108  [-3.19984283123631e-05, -0.01204727403819561, ...      8    0.830207   \n",
       "40   [0.007092211861163378, -0.020531129091978073, ...      9    0.829974   \n",
       "66   [0.005820663180202246, -0.026005927473306656, ...      8    0.828496   \n",
       "114  [-0.0025629678275436163, -0.026948552578687668...      8    0.827070   \n",
       "117  [-0.00697443587705493, -0.002737079979851842, ...      8    0.826591   \n",
       "28   [0.014130823314189911, -0.022022755816578865, ...      9    0.825649   \n",
       "80   [-0.004884935915470123, -0.020655907690525055,...      8    0.825517   \n",
       "113  [-0.004788630176335573, -0.019712286069989204,...      8    0.825159   \n",
       "50   [-0.00032217783154919744, -0.03402600064873695...      9    0.823419   \n",
       "115  [-0.0063687595538794994, -0.006055430509150028...      8    0.823356   \n",
       "47   [0.01376290526241064, -0.018722163513302803, -...      9    0.823351   \n",
       "97   [-0.0002861587272491306, -0.021342789754271507...      8    0.821715   \n",
       "92   [0.0020415757317095995, -0.015265116468071938,...      9    0.821227   \n",
       "68   [0.011701255105435848, -0.029144732281565666, ...      8    0.820909   \n",
       "\n",
       "                            answer  \n",
       "90   No relevant information here.  \n",
       "67   No relevant information here.  \n",
       "46   No relevant information here.  \n",
       "87   No relevant information here.  \n",
       "45   No relevant information here.  \n",
       "33   No relevant information here.  \n",
       "37   No relevant information here.  \n",
       "75   No relevant information here.  \n",
       "51   No relevant information here.  \n",
       "74   No relevant information here.  \n",
       "98   No relevant information here.  \n",
       "108  No relevant information here.  \n",
       "40   No relevant information here.  \n",
       "66   No relevant information here.  \n",
       "114  No relevant information here.  \n",
       "117  No relevant information here.  \n",
       "28   No relevant information here.  \n",
       "80   No relevant information here.  \n",
       "113  No relevant information here.  \n",
       "50   No relevant information here.  \n",
       "115  No relevant information here.  \n",
       "47   No relevant information here.  \n",
       "97   No relevant information here.  \n",
       "92   No relevant information here.  \n",
       "68   No relevant information here.  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d865229-4fbf-4d82-9345-e09702c37472",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433eb096-918c-4ad3-850d-87632ec5f8cb",
   "metadata": {},
   "source": [
    "Here we look for KG software by asking \"What are examples of the current best knowledge graph software in the market?\".  Results are not mind-blowing, but it should be mentioned that we are only evaluating 25 candidate snippets due to time/cost and design of this experiment.  So results are pretty decent, particularly in some of the examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "40260858-dc4c-438a-a128-e09dfa10468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best knowledge graph software', 'top knowledge graph software', 'knowledge graph solutions', 'current market trends in Knowledge Graphs', 'examples of successful Knowledge Graph implementations', 'Knowledge Graph technology reviews', 'comparison of popular Knowledge Graph tools and platforms ', 'list of leading companies using Knowledge graphs for their products or services ', 'advantages and disadvantages to different types of Knowlegegraph technologies']\n",
      "total urls: \n",
      "67\n",
      "df created with length:\n",
      "8443\n",
      "df_urls done\n",
      "url\n",
      "\n",
      "snippet_id\n",
      "\n",
      "text\n",
      "\n",
      "embedding\n",
      "\n",
      "score\n",
      "\n",
      "similarity\n",
      "\n",
      "search_df-done\n",
      "1269.8911747932434\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "my_question = \"What are examples of the current best knowledge graph software in the market?\"\n",
    "urls_per_search = 10 # How many urls to fetch from each google search, so total urls =this*number_of_proposed_searches_by_gpt3 minus any duplication\n",
    "top_m_urls = 15 # Once scored by credibility, how many to keep\n",
    "top_n_snippets = 25 # many snippets per url. How many to send to gpt3 as candidates for containing answer\n",
    "sdf = run_search(my_question, urls_per_search, top_m_urls, top_n_snippets, pprint = False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "895095cb-bc97-4848-a104-596e640576f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/topics/knowledge-graph\n",
      "SCORE:\n",
      "8\n",
      "IBM Cloud with Red Hat, Watson AI and open source code or visual modeling.\n",
      "https://www.ontotext.com/knowledgehub/webinars/state-of-kg-adoption/\n",
      "SCORE:\n",
      "7\n",
      "GraphDB, Ontotexts free application\n",
      "https://enterprise-knowledge.com/what-is-an-enterprise-knowledge-graph-and-why-do-i-want-one/\n",
      "SCORE:\n",
      "7\n",
      "Some of the more prominent examples of knowledge graphs are Google's implementation and LinkedIn.\n",
      "https://enterprise-knowledge.com/wireframes-visualize-knowledge-graphs/\n",
      "SCORE:\n",
      "7\n",
      "1. As a researcher, I need to identify experts in a particular field by browsing related webinars, publications, conferences, committees, HR data and other such entities; 2. As a lab equipment purchaser I need to access all available content about specific product category so that can make the most informed buying decision possible; 3.As a data scientist I need to see how various financial institutions replied on same regulatory form and be able traverse relationship\n",
      "https://neo4j.com/use-cases/knowledge-graph/\n",
      "SCORE:\n",
      "8\n",
      "Neo4j\n",
      "https://www.ibm.com/topics/knowledge-graph\n",
      "SCORE:\n",
      "8\n",
      "Examples of current best knowledge graph software in the market include Web Ontology Language (OWL) and Resource Description Framework (RDF).\n",
      "https://neo4j.com/use-cases/knowledge-graph/\n",
      "SCORE:\n",
      "8\n",
      "Neo4j, POLE, Amundsen\n",
      "https://dmccreary.medium.com/enterprise-knowledge-graph-trends-for-2021-201cbd7ad532\n",
      "SCORE:\n",
      "7\n",
      "Major cloud providers continued to promote their graph-based products, such as Gremlin.\n",
      "https://enterprise-knowledge.com/how-to-build-a-knowledge-graph-in-four-steps-the-roadmap-from-metadata-to-ai/\n",
      "SCORE:\n",
      "7\n",
      "Google, Amazon, Alexa and other chatbots are examples of the current best knowledge graph software in the market.\n",
      "https://enterprise-knowledge.com/how-to-build-a-knowledge-graph-in-four-steps-the-roadmap-from-metadata-to-ai/\n",
      "SCORE:\n",
      "7\n",
      "Knowledge graphs, backed by a graph database and a linked data store.\n",
      "https://dmccreary.medium.com/enterprise-knowledge-graph-trends-for-2021-201cbd7ad532\n",
      "SCORE:\n",
      "7\n",
      "Cosine Similarity, Field Programmable Gate Arrays (FPGA) hardware\n",
      "https://www.technologyreview.com/2020/09/04/1008156/knowledge-graph-ai-reads-web-machine-learning-natural-language-processing/\n",
      "SCORE:\n",
      "8\n",
      "Google started using knowledge graphs a few years ago.\n"
     ]
    }
   ],
   "source": [
    "for index, row in sdf[sdf['answer']!='No relevant information here.'].iterrows():\n",
    "    print(row['url'])\n",
    "    print('SCORE:')\n",
    "    print(row['score'])\n",
    "    #print(row['text'])\n",
    "    print(row['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3af064-0f21-465c-862c-095a34c11438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python38",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
